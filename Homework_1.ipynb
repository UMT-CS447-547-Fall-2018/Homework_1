{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning - Homework 1 (due Sep. 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: Legal reasoning (from Murphy 2.2).\n",
    "\n",
    "Suppose a crime has been committed. Blood is found at the scene for which there is no innocent explanation. It is of a type which is present in 1% of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. The prosecutor claims: “There is a 1% chance that the defendant would have the crime blood type if he\n",
    "were innocent. Thus there is a 99% chance that he guilty”. This is known as the prosecutor’s fallacy.\n",
    "What is wrong with this argument?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Part A - Answer</strong><br><br>\n",
    "Let $E$ be the event that the defendant is guilty <br>\n",
    "Let $X$ be the event that the blood type is a match\n",
    "\n",
    "Here, the prosecutor claims $P(X)=P(E|X)$\n",
    "\n",
    "However, according to Bayes, $P(E|X) = \\frac{P(X|E)P(E)}{P(X)}$\n",
    "\n",
    "* $P(E)$ is the prior evidence that a person is guilty which depends on how many people had access to the crime scene. \n",
    "\n",
    "* $P(X|E)$ is the likelihood that the blood type is a match given that the defendant is guilty (in this case, for the example I give I'm going to assume this is 100%)\n",
    "\n",
    "* $P(X)$ is the probability that any given person has the rare blood type\n",
    "\n",
    "The prosecutor mistakenly concludes that the odds of a person with a matching blood type is equal to the probability that an individual person might have the rare blood type. But, how can we know that there weren't hundreds of people exposed to the crime scene of which there were a several individuals who had the rare blood type? If we change our thinking, then we can see the flaw in our logic. If we knew 800 people had been exposed to the scene, then we could conclude that 8 of them had the matching blood type. If we assume our likelihood $P(X|E) = 1$, then to solve $P(E|X$ we would calculate $\\frac{1 * \\frac{1}{.01 * 800}}{.01}$ which would mean that there really is only a $12.5$% chance that the defendant is guilty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The defender claims: “The crime occurred in a city of 800,000 people. The blood type would be\n",
    "found in approximately 8000 people. The evidence has provided a probability of just 1 in 8000 that\n",
    "the defendant is guilty, and thus has no relevance.” This is known as the defender’s fallacy. What is\n",
    "wrong with this argument?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Part B - Answer</strong><br><br>\n",
    "\n",
    "Let $E$ be the event that the defendant is guilty <br>\n",
    "Let $X$ be the event that the blood type is a match\n",
    "\n",
    "* $P(E)$ is the prior evidence that a person is guilty which depends on how many people had access to the crime scene. \n",
    "\n",
    "* $P(X|E)$ is the likelihood that the blood type is a match given that the defendant is guilty (I'm going to assume this is 100% for simplicity in my arguments)\n",
    "\n",
    "* $P(X)$ is the probability that any given person has the rare blood type\n",
    "\n",
    "Here, the defender claims the posterior probability is the same as the prior probability, $P(E|X)=P(E)$ (the probability of a person being guilty given that they have matching blood types is equal to the prior probability that the person is guilty). However, if we look at Bayes thorem, we can obviously see that the defender fails to take into account the probability that the blood type is a match, ${P(X)}$, in the denominator of the equation.\n",
    "\n",
    "$P(E|X) = \\frac{P(X|E)P(E)}{P(X)}$\n",
    "\n",
    "If the defender divided the result of $\\frac{1}{8000}$ by $P(X)$, he would have had the right answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Suppose that forensic analysis tells us that with 98% probability, the blood found at the scene belongs to the perpetrator.  Given the information presented in the above two questions, determine the posterior probability the the defendent is guilty, given that the defendent's blood type matches that found at the crime scene *and* that the defendent was one of only 5 people with access to the crime scene.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Part C - Answer</strong>\n",
    "<br><br>\n",
    "*Bayes Theorem* \n",
    "<br><br>\n",
    "$P(E|X) = \\frac{P(X|E)P(E)}{P(X)}$\n",
    "<br><br>\n",
    "We want to find the posterior probability ${P(E|X)}$\n",
    "<br><br>\n",
    "We know:\n",
    "* likelihood - $P(X|E) = .98$\n",
    "* prior - $P(X) = \\frac{1}{5}$\n",
    "* $P(X) = .01$\n",
    "\n",
    "Plugging these values into Bayes Theorem we get:\n",
    "\n",
    "$P(E|X) = \\frac{.98 * \\frac{1}{5}}{.01}$\n",
    "\n",
    "$P(E|X) = 19.6$%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One use of the naive Bayes classifier, which is still in practical use today, is as a spam filter.  Consider the corpus of text messages packaged with this homework, which are each labelled as either 'spam' or 'ham'.  In this case, naive Bayes utilizes a Bernoulli model that quantifies the probability of a given word given that the message is either spam or ham.  For example, investigating the text messages here, we find that the word *draw* shows up in spam 27 times, yet in ham only 5.  Thus, we have that\n",
    "$$ P(X=\\mathrm{draw}|Y=\\mathrm{ham}) = \\frac{5}{5+27}. $$\n",
    "\n",
    "While this is not particularly strong evidence on its own, we can create a powerful classifier by using the naive assumption in conjunction with all the words in a given message:\n",
    "$$ P(Y=\\mathrm{ham}|\\hat{X}) \\propto P(Y=\\mathrm{ham}) \\prod_{i=1}^n P(X=x_i|Y=\\mathrm{ham}), $$\n",
    "$$ P(Y=\\mathrm{spam}|\\hat{X}) \\propto P(Y=\\mathrm{spam}) \\prod_{i=1}^n P(X=x_i|Y=\\mathrm{spam}), $$\n",
    "where $x_i$ are the words in a given message. \n",
    "\n",
    "Your task is to write such a classifier.  I have taken the somewhat tedious step of parsing the data for you, yielding the variables *word_dictionary*, which contains the ham and spam counts for each word, as well as *training_labels*, which provides the spam/ham labels for each text message.  I have also parsed a set of test data: *test_messages* is a list, each entry containing another list of the words in the text message, as well as *test_labels* which contains the spam/ham label for each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Maps from 'ham' or 'spam' strings to zero or one\n",
    "def mapper(s):\n",
    "    if s=='spam':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Read in the text file\n",
    "f = open('SMSSpamCollection','r')\n",
    "lines = f.readlines()\n",
    "\n",
    "# Break out the test data\n",
    "test_lines = lines[:len(lines)//5]\n",
    "lines = lines[len(lines)//5:]\n",
    "\n",
    "# Instantiate the frequency dictionary and an array to\n",
    "# record whether the line is ham or spam\n",
    "\n",
    "word_dictionary = {}\n",
    "# this is an example of what the work dictionary will eventually look like\n",
    "# { sale: [(# times word shows up in span message), (#times word shows up in ham message)]}\n",
    "# minimum of count of a word appearing is 1, which eliminates the difficulty of dividing by 0\n",
    "#     this is also known as regularization, prevents one word from having too much influence\n",
    "\n",
    "training_labels = np.zeros(len(lines),dtype=int) # this is just an array of 0's [0,0,0,....0,0,0]\n",
    "\n",
    "# Loop over all the training messages\n",
    "for i,l in enumerate(lines):\n",
    "    # Split into words\n",
    "    l = l.lower().split()\n",
    "    \n",
    "    # Record the special first word which always ham or spam\n",
    "    if l[0]=='ham':\n",
    "        training_labels[i] = 1\n",
    "    # For each word in the message, record whether the message was ham or spam\n",
    "    for w in l[1:]:\n",
    "        # If we've never seen the word before, add a new dictionary entry\n",
    "        if w not in word_dictionary:\n",
    "            word_dictionary[w] = [1,1] # regularize, set both ham and spam values equal to 1 to start off with\n",
    "        word_dictionary[w][mapper(l[0])] += 1 # if it's spam increment first value in array, if it's ham increment second value in array\n",
    "        \n",
    "# Loop over the test messages\n",
    "test_labels = np.zeros(len(test_lines),dtype=int)\n",
    "test_messages = []\n",
    "for i,l in enumerate(test_lines):\n",
    "    l = l.lower().split()\n",
    "    if l[0]=='ham':\n",
    "        test_labels[i] = 1\n",
    "    test_messages.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have provided code skeletons.  Your job is to make the code skeletons into an operational naive Bayes spam detector.  (you may discard these skeletons if you would prefer to code this from scratch).  Note that lines where you will need to change the code are marked with a '#!'.\n",
    "\n",
    "Your first task is train the model:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the prior P(Y=ham) ?\n",
    "numberOfHamMessages = np.count_nonzero(training_labels == 1) # number of times ham message shows up\n",
    "numberOfSpamMessages = np.count_nonzero(training_labels == 0) # number of spam messages\n",
    "totalNumberOfMessages = training_labels.size # total number of messages\n",
    "\n",
    "ham_prior = numberOfHamMessages/totalNumberOfMessages # None!\n",
    "\n",
    "# What are the class probabilities P(X=word|Y=ham) for each word?\n",
    "ham_likelihood = {}\n",
    "for key,val in word_dictionary.items():\n",
    "    ham_likelihood[key] = (val[1] / (val[0] + val[1])) # None!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to make predictions on a set of test examples which were held back from the training procedure (see *test_messages* variable).  For each of these messages, compute the ham and spam probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to hold the ham and spam posteriors\n",
    "posteriors = np.zeros((len(test_lines),2))\n",
    "\n",
    "# Loop over all the messages in the test set\n",
    "for i,m in enumerate(test_messages):\n",
    "    posterior_ham = 1.0 \n",
    "    posterior_spam = 1.0 \n",
    "    #! Don't forget to include the prior!\n",
    "    # Loop over all the words in each message\n",
    "    for w in m:\n",
    "        # #! What is the purpose of this try/except handler? \n",
    "        # ANSWER: There may be words in the test data that we didn't see in the training data\n",
    "        try:\n",
    "            posterior_ham *= (ham_prior * ham_likelihood[w]) #!\n",
    "            posterior_spam *= ((1-ham_prior) * (1-ham_likelihood[w])) #! <\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    # Notice the normalization factor (denominator) \n",
    "    # to turn these into proper probabilities!\n",
    "    posteriors[i,0] = posterior_spam/(posterior_spam + posterior_ham)\n",
    "    posteriors[i,1] = posterior_ham/(posterior_spam + posterior_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make a ham/spam prediction based on your posterior probabilities.  Compare these to the labels contained in test_labels.  Report the accuracy of your classifier as percentage correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Accuracy: 84.91921005385996\n"
     ]
    }
   ],
   "source": [
    "# We need to make an assumption about whether to classify any given word in our posteriors as spam or ham\n",
    "# so I am creating a method that accepts two parameters and returns ham/spam based on which posterior probability\n",
    "# is greater.\n",
    "def hamOrSpam(posteriorSpam, posteriorHam):\n",
    "    if(posteriorSpam > posteriorHam):\n",
    "        return mapper('spam')\n",
    "    elif(posteriorHam >= posteriorSpam):\n",
    "        return mapper('ham')\n",
    "\n",
    "# now we need to loop back through the test data and compare our models prediction to what the actual label for the \n",
    "# message is. \n",
    "numberCorrect = 0\n",
    "numberWrong = 0\n",
    "\n",
    "for i,line in enumerate(test_messages):\n",
    "    if(mapper(line[0]) == hamOrSpam(posteriors[i][0], posteriors[i][1])):\n",
    "        numberCorrect += 1\n",
    "    else:\n",
    "        numberWrong += 1\n",
    "        \n",
    "classifierAccuracy = (numberCorrect / (numberCorrect + numberWrong)) * 100\n",
    "print('Classifier Accuracy: ' + str(classifierAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-decoration: underline; color: #333\">Summary</h1>\n",
    "<h4 style=\"color: #333;\">Assumptions</h4>\n",
    "I assumed that a message was ham/spam depending on which posterior probability was greater. The logic for this is in the method hamOrSpam() that I created.\n",
    "<br>\n",
    "<h4 style=\"color: #333;\">Conclusion</h4>\n",
    "Our model is 84.92% accurate in predicting the correct category for our test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
