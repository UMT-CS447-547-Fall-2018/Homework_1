{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning - Homework 1 (due Sep. 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: Legal reasoning (from Murphy 2.2).\n",
    "\n",
    "Suppose a crime has been committed. Blood is found at the scene for which there is no innocent explanation. It is of a type which is present in 1% of the population.  The defendant is known to have this rare blood type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. The prosecutor claims: “There is a 1% chance that the defendant would have the crime blood type if he\n",
    "were innocent. Thus there is a 99% chance that he guilty”. This is known as the prosecutor’s fallacy.\n",
    "What is wrong with this argument?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short Answer:\n",
    "\n",
    "$P(I|B)$ != $P(B|I)$\n",
    "\n",
    "###### Long Answer:\n",
    "\n",
    "By this line of reasoning, anyone with the crime blood type could also be argued to have a 99% chance of being guilty.And presumably there is a single(or a few) person that commited the crime and therefore it is nonsensical to argue that everyone with this blood type is extremely likely to have comitted the crime (This would violate the law of total Probability). \n",
    "\n",
    "Furthermore, it is a fallacy to conclude that P(B|I) equals P(I|B) becuase you are ignoring both the prior and the evidence term of Bayes' Rule which allows you to 'invert' conditional probabilities. This ratio of prior to evidence determines how much a naive invert of conditional probabilities would be off. In our example P(I)/P(B) is near 100 and when multiplied by the likelihood of .01 we get an almost 1.00 probability of innocence given blood type. This is modeling as if a random person is pulled from the city and is awaiting trial(we are using an uninformitative prior)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The defender claims: “The crime occurred in a city of 800,000 people. The blood type would be\n",
    "found in approximately 8000 people. The evidence has provided a probability of just 1 in 8000 that\n",
    "the defendant is guilty, and thus has no relevance.” This is known as the defender’s fallacy. What is\n",
    "wrong with this argument (HINT: What happens to the prior in this case if there is *other* evidence presented)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short Answer:\n",
    "\n",
    "This is neglecting all prior evidence for the suspect and assuming anyone in the subset of 8000 is equally likely to be innocent. And it assumes police were pulling out of the 8000 people subpopulation (as if they know who has the blood type and who doesn't) at random and therefore, one in 8000 of the people would be guilty. However, when combined with additional evidence the $\\frac{1}{8000}$ will be transformed(multiplied by the prior) to represent our updated belief in guilt and therefore is very much relevant to determine the guilt of the criminal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Suppose that forensic analysis tells us that that the blood test has 98% sensitivity (true positive rate) and a 1% false positive rate.  Given the information presented in the above two questions, determine the posterior probability the the defendent is guilty, given that the defendent's blood type matches that found at the crime scene *and* that the defendent was one of only 5 people with access to the crime scene *and* that there is no other evidence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "##### $0.96$ or $96$% of guilt given evidence\n",
    "\n",
    "###### Bayes:\n",
    "$P(G|+) = \\frac{P(+|G)P(G)}{P(+)}  =  0.96$\n",
    "\n",
    "###### Term breakdown:\n",
    "\n",
    "$P(+)$ is the $P$ of testing positive for the specific blood type. $0.204$\n",
    "\n",
    "$P(G)$ is the prior probability/belief of guilt.  $0.2$\n",
    "\n",
    "$P(+|G)$ is the $P$ of testing positive given guilty. $0.98$\n",
    "\n",
    "###### Sum rule for $P(+)$:\n",
    "\n",
    "$P(+) = P(+|G)P(G) + P(+|I)P(I)$\n",
    "\n",
    "$P(+) = 0.98*0.2  +  0.01*0.8  =  0.204 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One use of the naive Bayes classifier, which is still in practical use today, is as a spam filter.  Consider the corpus of text messages packaged with this homework, which are each labelled as either 'spam' or 'ham'.  In this case, naive Bayes utilizes a Bernoulli model that quantifies the probability of a given word given that the message is either spam or ham.  For example, investigating the text messages here, we find that the word *draw* shows up in spam 27 times, yet in ham only 5.  Thus, we have that\n",
    "$$ P(X=\\mathrm{draw}|Y=\\mathrm{ham}) = \\frac{5}{5+27}. $$\n",
    "\n",
    "While this is not particularly strong evidence on its own, we can create a powerful classifier by using the naive assumption in conjunction with all the words in a given message:\n",
    "$$ P(Y=\\mathrm{ham}|X=x) \\propto P(Y=\\mathrm{ham}) \\prod_{i=1}^n P(X_i=x_i|Y=\\mathrm{ham}), $$\n",
    "$$ P(Y=\\mathrm{spam}|X=x) \\propto P(Y=\\mathrm{spam}) \\prod_{i=1}^n P(X_i=x_i|Y=\\mathrm{spam}), $$\n",
    "where $x_i$ are the words in a given message. \n",
    "\n",
    "Your task is to write such a classifier.  I have taken the somewhat tedious step of parsing the data for you, yielding the variables *word_dictionary*, which contains the ham and spam counts for each word, as well as *training_labels*, which provides the spam/ham labels for each text message.  I have also parsed a set of test data: *test_messages* is a list, each entry containing another list of the words in the text message, as well as *test_labels* which contains the spam/ham label for each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Maps from 'ham' or 'spam' strings to zero or one\n",
    "def mapper(s):\n",
    "    if s=='spam':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Read in the text file\n",
    "f = open('SMSSpamCollection','r')\n",
    "lines = f.readlines()\n",
    "\n",
    "# Break out the test data\n",
    "test_lines = lines[:len(lines)//5]\n",
    "lines = lines[len(lines)//5:]\n",
    "\n",
    "# Instantiate the frequency dictionary and an array to\n",
    "# record whether the line is ham or spam\n",
    "word_dictionary = {}\n",
    "training_labels = np.zeros(len(lines),dtype=int)\n",
    "\n",
    "# Loop over all the training messages\n",
    "for i,l in enumerate(lines):\n",
    "    # Split into words\n",
    "    l = l.lower().split()\n",
    "    # Record the special first word which always ham or spam\n",
    "    if l[0]=='ham':\n",
    "        training_labels[i] = 1\n",
    "    # For each word in the message, record whether the message was ham or spam\n",
    "    for w in l[1:]:\n",
    "        # If we've never seen the word before, add a new dictionary entry\n",
    "        if w not in word_dictionary:\n",
    "            word_dictionary[w] = [1,1]\n",
    "        word_dictionary[w][mapper(l[0])] += 1\n",
    "        \n",
    "# Loop over the test messages\n",
    "test_labels = np.zeros(len(test_lines),dtype=int)\n",
    "test_messages = []\n",
    "for i,l in enumerate(test_lines):\n",
    "    l = l.lower().split()\n",
    "    if l[0]=='ham':\n",
    "        test_labels[i] = 1\n",
    "    test_messages.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have provided code skeletons.  Your job is to make the code skeletons into an operational naive Bayes spam detector.  (you may discard these skeletons if you would prefer to code this from scratch).  Note that lines where you will need to change the code are marked with a '#!'.\n",
    "\n",
    "Your first task is train the model:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham_prior:\n",
      "0.8701793721973095\n"
     ]
    }
   ],
   "source": [
    "# for loop to calculate len of 1 and 0's in training_labels\n",
    "ham_count =0\n",
    "spam_count=0\n",
    "for i in range(len(training_labels)):\n",
    "    if training_labels[i] == 1:\n",
    "        ham_count += 1\n",
    "    else:\n",
    "        spam_count += 1\n",
    "#print (ham_count, spam_count)\n",
    "\n",
    "#What is the prior P(Y=ham) ?\n",
    "ham_prior = ham_count/(spam_count+ham_count)    #!\n",
    "print (\"ham_prior:\")\n",
    "print (ham_prior)\n",
    "\n",
    "# What are the class probabilities P(X=word|Y=ham) for each word?\n",
    "ham_likelihood = {}\n",
    "for key,val in word_dictionary.items():\n",
    "    ham_likelihood[key]=val[1]/(val[0]+val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to make predictions on a set of test examples which were held back from the training procedure (see *test_messages* variable).  For each of these messages, compute the ham and spam probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.26095525e-14 1.00000000e+00]\n",
      " [2.65423069e-07 9.99999735e-01]\n",
      " [9.99999996e-01 3.80127070e-09]\n",
      " [1.90853281e-13 1.00000000e+00]\n",
      " [4.51555027e-17 1.00000000e+00]]\n",
      "0.006662435493857435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'$P(Spam)$')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucHXV9//HXe3ezu4HcSUgCSQhIEKMBlQW1LT9RUSFVUAoKasVKRR8tXqqoWFtFqvVXLz+tLaipCirKvSLSWLQK9gEKEq6BIBgIkIRcyW1z2d1s8vn9MXOWycmZ3XOW3XPZfT8fj33smZnvmfl8v9855zPznXPOKCIwMzMrpanWAZiZWf1ykjAzs1xOEmZmlstJwszMcjlJmJlZLicJMzPL5SQxSkm6WNKVg3zueyTd3s/yn0s6t1RZSdslHTGY7VYY41hJP5O0VdJ1w729RiTpSUknD/K5D0s6aYhDsjrUUusArHySngSmA3uAHcBi4IMRsb2WcRWLiFP7WTau8FjSFcCqiPiHYQjjTJK2Oigieodh/aNaRLy41jFYdfhMovG8OX2jfTlwPLDfG6wSo71vDwMec4Iwe35G+xtJw4qI1cDPgZcASLpN0hck3QHsBI6QdIikmyRtkrRc0vuKVtMu6RpJnZLulXRsYYGkiyQ9ni5bJumtRc+VpH9Lh3P+IOl1mQW3SfrrUnFLCklHSjofeCfwiXQI6meSPi7phqLy/ybp6znrelG6rS3p8Mdp6fzPAZ8B3p6u+7wSz71Y0nWSrkzruFTSUZI+JWm9pJWS3pApP1HSdyWtkbRa0uclNafLjpT0m7QtNkq6ptBAkr6Wrm+rpAclFfrrzyXdJ2lbuq2Li+J7t6SnJD0r6R+zQ0OSmjL986ykayVNSZe1p3V6Nm2XuyVNL9V+qePT/t0s6XJJ7ZkY3iTp/nQ9v5V0TGZZNp6L0xh+kLblw5I6MmVfnta1M23zayR9PqdPS7ZluiwkfUjSE+myLys9GJL0Akm/Tuu9UdKPJE0qivfjaR/sSPtyupKh0U5J/yNpcj/tNHpFhP8a5A94Ejg5fTwbeBj4p3T6NuBp4MUkw4hjgN8AlwHtwEuBDcDr0vIXA7tJhmXGABcCK4Ax6fKzgENIDiTeTjK8NTNd9h6gF/i79LlvB7YCUzKx/HWm7O2ZOgRwZPr4CuDzmWUz0+1MSqdbgPXAcSXaYgywHPh7oBV4LdAJvDBTvyv7acuLgS7gjel2fpDW/9Pput8HrMiUvxH4NnAgcDDwe+D96bKr0uc1pW39Z+n8NwL3AJMAAS/KtOFJwIL0OccA64C3pMvmA9uBP0vr9pW0rwp9/xHgTmAW0JbGdVW67P3Az4ADgGbgOGBCP/vTQyT70hTgjkJ/kJyprgdeka7n3LR8W4l9sdCWC9OyXwTuTJe1Ak8BH07b9QygJ9vvRTGVbMvMvnNrGusc4DGe28+OBF6ftsc04H+BrxfV9U6SIchD07rdC7wsfc6vgc/W+jVej381D8B/FXRWsqNvB7akL7zLgLHpstuASzJlZ5NcuxifmfdF4Ir08cWFF3I63QSsAU7M2fb9wOnp4/cAzwDKLP898JeZWCpOEum8nwPvSx+/CViWE8+JwFqgKTPvKuDiTP0GShK/zEy/OW3b5nR6fBrrpPSNpbvQ1unyc4Bb08c/ABYBs4q28dr0jeyV2Thz4vk68LX08WdI3/TT6QNI3lgLb8qPkCb7dHomSRJpAd4L/BY4psz96QOZ6YXA4+njb5IegGSWPwq8OvPcbJL4n0y5+cCu9PH/AVYX7Su3F/d7ZlnJtszsO6dkpv8G+FXOet4C3FdU13dmpm8AvpmZ/iBw43C9dhv5z8NNjectETEpIg6LiL+JiF2ZZSszjw8BNkVEZ2beUyRHUfuVj4i9wKr0eYXhjsJQwxaSYa2pmeeujvTVlVn3Ic+rZonvA+9KH78L+GFOuUOAlWnc2RgOzSlfyrrM413AxojYk5kGGEdyfWMMsCbTHt8mOaMA+ATJmcLv06GW9wJExK+BfwcuBdZJWiRpAoCkV0i6VdIGSVuBD/Bc+x7Cvn2zE3g2E+thwE8ysTxCckAwnaS9bgGulvSMpC9JGtNPG2T3mWwfHgZ8rLCNdDuzye/jtZnHO0mGMlvS8sX7ykrylWzLgeKVdLCkq9OhwG3Aley7v8L+/V08PQ7bj5PEyJJ9IT4DTJE0PjNvDslRXcHswoN0bHcW8Iykw4D/AC4g+XTQJJJhCWWee6ik7PScdJuDjbfgRuCYdOz+TcCPcp77DDBb+16gL67fUFlJciYxNU3QkyJiQqSf8ImItRHxvog4hGS45zJJR6bLvhERx5EMAx4FfDxd54+Bm4DZETER+BbPte8akr4Ako/zAgcVxXNqJpZJEdEeEasjYndEfC4i5gN/QtKG7+6nbrMzj7N9uBL4QtE2DoiIqypot0JdiveV2XmF+2vLAeL9Isn+dExETCA5wMhu0wbJSWKEioiVJMMOX0wvZh4DnMe+b7rHSTojPeL7CMkb4Z0k4+5Bcg0DSX9FeoE842DgQ5LGSDqLZLx9cYVhrgP2+c5ERHQB15O8if4+Ip7Oee5dJNcvPpHGcBLJkNHVFcYwoIhYA/wC+KqkCemF4xdIejWApLMkFd7UN5O03R5Jx6dnDGPSWLtIjvghGc7aFBFdkk4A3pHZ5PXAmyX9iaRW4HPs+4b3LeALaTJH0jRJp6ePXyNpgZKL6ttIhqH2kO9vJc1KL3z/PVC4UPwfwAfS+CXpQCUX28fnr6qk36Xbv0BSSxrnCXmF89oyU+TjkiZLmk1ynaMQ73jSoVhJh/JcMrbnyUliZDsHmEtytPUTkgtzv8ws/ynJRefNwF8CZ6RHosuAr5K8wNeRXGC9o2jddwHzgI3AF4AzI+JZKvNdYH46nHFjZv73023mDTURET3AacCpaQyXAe+OiD9UGEO53k1yEXYZSXtdT3ItAJKPIt8laTvJ2cGHI2IFMIHkzXYzydDIsyQXoSEZT79EUifJNYhrM3V7mGSM/GqSI/FOkgut3WmRf02384v0+XeSXGAGmJHGto1kGOo3JEMveX5MkgCfSP8+n8awhOTi/b+n8S8nub5UkbSfziA5QNlCcoR/c6YuxfLasuCnJB8GuB/4L5J9CJJE+nKSD1D8F/CflcZqpWnfoUKz2pM0B/gDMCMittU6nlqTNI7kDXZe0RtmQ5J0F/CtiLi8wucFSRssH57IrBSfSVhdSa8xfBS4ejQnCElvlnSApANJzj6WknxCp+FIerWkGelw07kkH/n971rHZeXxz3JY3UjfENeRDM2cUuNwau10kuE2AUuAs6NxT/tfSDKcNg54nGRock1tQ7JyebjJzMxyebjJzMxyNfxw09SpU2Pu3Lm1DsPMrKHcc889GyNi2kDlGj5JzJ07lyVLltQ6DDOzhiLpqXLKebjJzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLFfVkoSk7ym5jeNDOcsl6RtKbrP5oKSXVys2MzMrrZpnElfQ/08tnEryq6LzgPNJ7oxlZmY1VLUkERH/C2zqp8jpwA8icScwSdLMfsqbmdkwq6drEoey760JV1HZrSgrtrOnlx/d9RSLfvM4H7nqXq64YwU7e3oHtZ7r71lV8rmlluVtt5z1bNzeVbJMf8+tNNbsNgqx/viupypqm3Lj2bi9i0/e8CAbt3f121Z52y8sv+KOFX1lhqItSpXJPi7EvXLTjorWUWzlph287du/47G12ypeT39tU2kbbNzeVXJd5a5noDgvv2MFF157/z79XGqbG7d38bFr7+eKO1bst69n67ty046+/abcOIqXFdZVajvlvsaKXzN5r89y2624PQb7+htK9fSN61K3Giz564OSzicZkmLOnDmD3uDipWv59E+eu0Ry4wNrGNc+hjOPm9XPs0qv58LrHgDY77mlluVtFxhwPW8/fjbX3L1yvzL9xVBprNltAH2xtrY0l9025cbz5Vse69vW8XOn9NtWpbZf3JatLc1AfjtWGmO2THa9dz+5iWvuXsmKjTv4/YpNZa+juMzHrnuQ36/YxPuvvJcVG3eUtZ67n9zEZ988v9+2qXR/yPZ5dl0DrWdnTy+Ll65l4YIZHNDast9zFi6Ywed+tqxv3c3NTX39XGqbX77lMW64dzU33LuaR9Z27rOvZ+t7wuFT+tr9X/7imH7rVir27LoeWLV1v+2Uel7eazlbl7zXZzlK9edA+3811FOSWMW+96+dRc49kyNiEbAIoKOjY9A/Y7twwQy6e/ewo6uXZc9s5aVzJrNwwYxBrSf7f6BlA223v/Wc9MKpHD93yn5l+ouh0liLt9HduweVse7BxPPxNx7V97/wJlOqrfK2X1i+u3cvrS1NA7ZjpTHm9d9JL5wKwAWveQF3rdhc8ToKvnrWMXzsugf5/Okv5sHV2wZcTyE5Ffonr20q3R9OeuFUjpk1cb91DbSeUm+chbh6evdw432ruebulZx+7EzGNDft08+ltvnxNx5F7569LDh0Im86duY++2G2vifOm8q/3/p43/7TX936228EvOHF0/fbTqnn5e0LhbocP3dK7uszq1RiLY6pVJ0H8940FKr6U+GS5gI3R0Tx/ZKR9OfABcBCklsxfiMicu+FW9DR0RH+7SYbLfLeYOotnuvvWcWF1z3AF976EtpamgeMt97qNZwKbfOVs46tyZlBgaR7IqJjoHJV6w1JVwEnAVMlrQI+C4wBiIhvAYtJEsRyYCfwV9WKzaxRHNDaUtM3lmJ58WSPhMt50y93eGwkKPcsr140/E2HfCZh9WA0HQkPB7df9ZV7JlFPn26yEWown5AZTpV8eqVchSPhxUvXDlWYo0rhjMQJov64R2zY1dtQQiWfXilXow0hmJXLScKGXb29gVby6ZVy1du1ArOh4uEmG3b1NpSQF08146y3IbjBGAl1sIE5SZjVwEi4hjES6mADq49DO7NRpt6G4AZjJNTBBuYzCbMqKgzRAHU1BDcY9TaMaMPDSSLDY6z1r9H7yEM01mh8CJBRbx/VtP01eh95iMYajZNEhl/A9a/R+8gflbVG4+GmjP7GWBt9mGOk8Dj40PO+bf1xkiiTx5KHn9+sasP7tvXHh2NlavRhjkbQ6NcbGpX3beuPk0SZPJY8/PxmVRv1sm/7l2Drk4ebrG74esPo5mGv+uRXo5nVBZ9J1icnCTOrC/Uy7GX78nCTmZnlcpIwM7NcThJmZpbLScLMzHI5SZiZWS4nCTMzy+UkYWZmuZwkzMwsl5OEmZnlcpIwM7NcThJmZpbLScLMzHI5SZiZWS4nCTMzy1XVJCHpFEmPSlou6aISy+dIulXSfZIelLSwmvGZVYPv5W2NpGpJQlIzcClwKjAfOEfS/KJi/wBcGxEvA84GLqtWfGbV4juwWSOp5k2HTgCWR8QTAJKuBk4HlmXKBDAhfTwReKaK8ZlVhe/AZo2kmkniUGBlZnoV8IqiMhcDv5D0QeBA4ORSK5J0PnA+wJw5c4Y8ULPh5DuwWSOp5jUJlZgXRdPnAFdExCxgIfBDSfvFGBGLIqIjIjqmTZs2DKGamRlUN0msAmZnpmex/3DSecC1ABHxO6AdmFqV6MzMbD/VTBJ3A/MkHS6pleTC9E1FZZ4GXgcg6UUkSWJDFWM0M7OMqiWJiOgFLgBuAR4h+RTTw5IukXRaWuxjwPskPQBcBbwnIoqHpMzMrEqqeeGaiFgMLC6a95nM42XAn1YzJjMzy+dvXJuZWS4nCTMzy+UkYWZmuZwkzMwsl5OEmZnlcpIwM7NcThJmZpbLScLMzHI5Sdio4Zv9mFXOScJGDd/sx6xyVf1ZDrNa8s1+zCrnJGGjhm/2Y1Y5DzeZmVkuJwkzM8vlJGFmZrmcJMzMLJeThJmZ5XKSMDOzXE4SZmaWy0nCzMxyOUmYmVkuJwkzsxpphB+ddJIwM6uRRvjRSf92k5lZjTTCj046SZiZ1Ugj/Oikh5vMzCyXk4SZmeVykjAzs1xOEmZmlstJwszMclU1SUg6RdKjkpZLuiinzNskLZP0sKQfVzM+MzPbV9U+AiupGbgUeD2wCrhb0k0RsSxTZh7wKeBPI2KzpIOrFZ+Zme2vmmcSJwDLI+KJiOgBrgZOLyrzPuDSiNgMEBHrqxifmZkVqWaSOBRYmZlelc7LOgo4StIdku6UdEqpFUk6X9ISSUs2bNgwTOGamVnFSULSgenQUcVPLTEviqZbgHnAScA5wHckTdrvSRGLIqIjIjqmTZs2iFDMzKwcAyYJSU2S3iHpvyStB/4ArEkvLH85vY5QjlXA7Mz0LOCZEmV+GhG7I2IF8ChJ0jAzsxoo50ziVuAFJBeUZ0TE7Ig4GDgRuBP4v5LeVcZ67gbmSTpcUitwNnBTUZkbgdcASJpKMvz0RFk1MTOzIVfOp5tOjojdxTMjYhNwA3CDpDEDrSQieiVdANwCNAPfi4iHJV0CLImIm9Jlb5C0DNgDfDwinq2gPmZmNoQUUXxZoJ/C0phSCaOWOjo6YsmSJbUOw8ysoUi6JyI6BipX9vckJH0HOEPSDpJrCQ8CD0bEvw0+TDMzq2eVfJnuRGB6ROyWdChwLHDM8IRlZmb1oJIkcScwGVgfEauB1cDiYYnKzMzqQiXfk1gE/EbShZJOlDRxuIIyM7P6UEmSuBK4luTs42+A30p6fFiiMjOzulDJcNOqiPhsdoaktiGOx8zM6kglZxL3S/pwdkZEdA9xPGZmVkcqOZOYDpws6ZPAvcADwP0Rcd2wRGZmZjVXdpKIiLdB3xDTi4EFwCsAJwkzsxGqki/THQS8DegCHgaujYjvD1dgZmZWe5Vck/gJMA34Z+DLwFZJjwxLVGZmVhcquSYxPiIukXRGRLxa0l8ARw5XYGZmVnuVnEl0pf+7JY2NiBuAhcMQk5mZ1YlKziS+ImkKyRfqvifpt+x/+1EzMxtByj6TiIgbImJTRHyV5DebZgOnD1tkZmZWc2UnCUmnSrpL0qPAm4GfRMTDwxeamZnVWiXXJC4DPgq8kuTH/r4s6ZxhicrMzOpCJdck1kXEHenj/5H0O+Au4KqhD8vMzOpBJWcST0r6vKTWdHo30DkMMZmZWZ2oJEkEcAawUtLtwHLgNknzhiUyMzOruUp+u+kcAEntwEtIbl96LPAdSUdExOzhCdHMzGqlkmsSAEREF7Ak/TMzsxFswOEmSb+S9OLM9GmS/kHSK4Y3NDMzq7VyrknMKnwfQtKfAD8E5gCXS3rrcAZnZma1VU6S2JZ5/G7gWxFxPnAS8MnhCMrMzOpDOUliuaQzJR0MvAX4KUBErAd8j2szsxGsnCTxd8D7gdXAvRHxWwBJY4DxwxibmZnVWDmfbloXEa+X1BQRezPzXwP8GkCSIiKGJUIzM6uZcs4kbpX0QWBW0fzbgGskfR84d6gDMzOz2ivnTOIU4L3AVZKOADYD7UAz8AvgaxFx//CFaGZmtTJgkki/PHcZcFl6HWIqsCsitgx3cGZmVlvlfJnuXEkbJW0CvgNsH2yCkHSKpEclLZd0UT/lzpQUkjoGsx0zMxsa5VyT+Efg9cDRwNPAPw9mQ5KagUuBU4H5wDmS5pcoNx74EMnPkJuZWQ2V9WW6iLgvItZHxD8CJwxyWycAyyPiiYjoAa6m9O1P/wn4EtA1yO2YmdkQKSdJzJR0vqQTJU0DxgxyW4cCKzPTq9J5fSS9DJgdETf3t6I0niWSlmzYsGGQ4ZiZ2UDK+XTTZ4FjgHcCC4BxkhYDDwAPRkS5d6ZTiXl9362Q1AR8DXjPQCuKiEUkt1Clo6PD388wMxsm5Xy6aVF2WtIskqSxAFhI+bcvXQVk7zkxC3gmMz2e5D4Vt0kCmAHcJOm0iPDPko8wO3t6Wbx0LQsXzOCA1op/sd7MqmQw95NYRfKGv7jCp94NzJN0OMlPfJwNvCOz3q0kH68FQNJtwIVOECPT4qVrufC6BwA487ji72maWb2o2iFcRPRKugC4heSLeN+LiIclXQIsiYibqhWL1d7CBTP2+W9m9UmN/pNLHR0dsWSJTzbqhYeRzBqDpHsiYsDvopXz6SazshWGkRYvXVvrUMxsCPhQz4aUh5HMRhYnCRtSB7S2+EK02Qji4SYzM8vlJGFmZrmcJMzMLJeThJmZ5XKSMDOzXE4SZmaWy0nCzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLJeThJmZ5XKSMDOzXE4SZmaWy0nCzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLJeThJmZ5XKSMDOzXE4SZmaWy0nCzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLFdVk4SkUyQ9Kmm5pItKLP+opGWSHpT0K0mHVTM+MzPbV9WShKRm4FLgVGA+cI6k+UXF7gM6IuIY4HrgS9WKz8zM9lfNM4kTgOUR8URE9ABXA6dnC0TErRGxM528E5hVxfisQe3s6eX6e1axs6e31qGYjTjVTBKHAisz06vSeXnOA35eaoGk8yUtkbRkw4YNQxiiNaLFS9dy4XUPsHjp2lqHYjbitFRxWyoxL0oWlN4FdACvLrU8IhYBiwA6OjpKrsNGj4ULZuzz38yGTjWTxCpgdmZ6FvBMcSFJJwOfBl4dEd1Vis0a2AGtLZx5nEcmzYZDNYeb7gbmSTpcUitwNnBTtoCklwHfBk6LiPVVjM3MzEqoWpKIiF7gAuAW4BHg2oh4WNIlkk5Li30ZGAdcJ+l+STflrM7MzKqgmsNNRMRiYHHRvM9kHp9czXjMzKx//sa1mZnlcpIwM7NcThJmZpbLSaKB+JvFZlZtThINxN8sNrNqq+qnm+z58TeLzazafCbRQArfLD6gtXq53UNcZqObk4T1y0NcZqObh5usXx7iMhvdnCSsX/7xPLPRzcNNZmaWy0nCzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLJeThJmZ5XKSMDOzXE4SZmaWy0nCBq2RfvyvkWKtZwO1Yy3aeTT0bS3r6CRRRxptZ2+kH/9rpFjr2UDtWIt2Hg19W8s6+reb6khhRwAa4veSGunH/xop1no2UDvWop1HQ9/Wso6KiKpvdCh1dHTEkiVLah3GkNjZ08vipWtZuGBGVe8ZYWajj6R7IqJjoHIebqojtbipUDU02jBao3I723BwkrBhNxrGjOuB29mGw8g6ZLW6NBrGjOuB2/k5HrodOm49G3a+cVF1uJ2f02gfAqlnThJmNuIM51nVaDtL8TUJMxtxhvNDIKPt2o+TxDAbiZ84qYc6DWUM9VCf0W6o+qAafblwwQy+ctaxo+baT1WThKRTJD0qabmki0osb5N0Tbr8LklzqxnfcBiqo456eSPb2dPL5362rOZHUkPZrvVQn9Hu+fTnzp5efnTXU/z4rqe48b7Vw96Xw3WWUi+v8WJVG1CT1AxcCrweWAXcLemmiFiWKXYesDkijpR0NvAvwNurFWMlyh2XLHdsdKD1PZ8LccXrHsyYauE5Pb17uObulbz9+Nk1PZIaqjHnxUvX7lefeh1zrte4hsLz6c/FS9fy6Z88BMAX3vqShj3Kr9uL7RFRlT/gVcAtmelPAZ8qKnML8Kr0cQuwkfRb4Xl/xx13XAyFHd2747olK2NH9+7c5Vfe+WT86M4n+x4f9smb43u3P7Hf8wZaVynXLVkZh33y5rhuycqScW3o3DXgOrPbzcZ7+e1PxGGfvDmuvPPJfrfVX3sUnnPlnU/mxlEc64bOXfu0WSGmy29/om9eXuyVtl9/z+9vfaWWFer60Wvui8tvf6Iv3qef3R6fuP6B2NC5q9/nl9umldjRvTs+cf0D/fZbf+0bEbGhc1fZ8ZeaP9g27k82pv729YH6MLuflVu37Hay6yjefqX7z0DKafOB2vf57EsFwJIo4727aj/LIelM4JSI+Ot0+i+BV0TEBZkyD6VlVqXTj6dlNuatd7A/y7Gzp5cf/u4pfnb/apCYObGdXz6ynpkT2xjf2sKWrh4AJraPYVt3L02INdu6ATh4/Bi6du9lW9ceJrQ3s61rD9MntDKxbQxbunro3r2XrV17mNjWxIHtY3j9/Oncsmwte/dG3/qmjG3l0IMOgAie2dxF7569dPb0Mu/g8azf2sWmXcm2hFjX2cPMiW0cPXMCG7Z1M2VcK4+u3UZEsr6tXbtpkpjYPoZH1+9gYlsT7a0trOtM6lCIcWJbEzMmjiUCtnbvZkJbC1u7du9Tz0ntYxBic1cP67Y9t911W/aPcWv3bo6YOo7lGzqTnSmNdVJ7M1u69jBxbAtbdyWnzkcfPI51nV1s3vXcqfRR0w5kx+49vGDaOP64vpM1W7s5+uBxbO3ezZqt3X3xCgGwN4Kt3bv7YixoahLNzWLp6m1MamuCpia27OplUlsTra3NNCHWpm04b/p4/riukwltLX3raGoSUye09c2PgLWdXWzr2rPPPnNAazM7e/YwthnmTh3HjMljeWxtJ6u3dDF5bAvzD5nY1xaFfgGYPLaVCFi3vZutu3qZObGNyWNbmTqhjRUbdvDGF0/nzsefpad3b8l+2dq1u2+fmjmxjYltY/raYsrYVqZNbOeP6zoh6NtHAaZPaE36P13f9q497Ny9l/YmmHDgGCa2j2H99h627upl/ozxSRvvDfZG9NW/sF9v7d4NAes6e5g+oZWmEGs6u/va9IGVW9i6q5fpE1o56IA2pk9qZ82mXWzt3s28g8ezaUcP0ya0sWbTLjZ39fT14drt3WzZuZspY1uYMXEsy9Z28pJDx/PQ6s592rSrZ88+9c/22aT2McyYPJZ1W7rYu/e597PCfjR9QmvhIDSp87YutnbvZebENtZs7Wby2BamjW/jsfU7kjLpfjupvZlp49v6yhfaorOnt2+/7969ly27epnc3szBE9oR6uubCW0tbOvu3a8/C21e6J9J7WOIgM6eXo6eMQEI7n36ufac3N5KZ08vq7d09e3ThdfamxbM5EtnHTOoM8tyf5ajmkniLOCNRUnihIj4YKbMw2mZbJI4ISKeLVrX+cD5AHPmzDnuqaeeqjie6+9Z1XdqZ2bWqL5y1rGDGp4qN0lUc2BzFTA7Mz0LeCanzCpJLcBEYFPxiiKjEWE6AAAGd0lEQVRiEbAIkjOJwQSzcMEMnt3e3Xcm8dqjD+axtdt4etMuevfs3e9MYsrY1r6jlewR9cbO7r6jl70RbOnqoUniBdPGs3xDJ81SWWcSe/cGTU3qOwIrnElMHtuKUN+y/s4kjpo+gfVbu/Y5UoP9j5SzR+bF9Sx1lJ7d7uPrt/OCaeNKnkkUx7puSxcAh0wZy549e3lsXfLcjZ1J3aZOaOtbX2Fe4Xm9e/bud9bQ35nEnKkHcPhBB/KT+1fRxL5tno2rVDv0N/+QKWP7+qipSbzyiCksfmgNE9uSo9dsu8w96MB+zySy+0yh/uWeSTRJvGjmRJqb6DvzLD6TKBxRb9jWvc9Re2F9LU1N++2L23v2cPSMCX3rLZxJZNs5r93z2i67Hw90JtHS0sSJ86Zyx/KNHDyxnfbmJo6eMYH7V27mkbWdfW0q4KjpE/peb+WcSZR6PRW//or3y+J1j2tt3ud1sTdinzOJwuv7l4+sY3xrS1lnEtt79vSdjRfaovhM4g9r990XW1qaeOURU7h56TN9+/SYlmZOe+khw379pZpnEi3AY8DrgNXA3cA7IuLhTJm/BRZExAfSC9dnRMTb+lvvSPoVWDOzaqm7M4mI6JV0AcnF6WbgexHxsKRLSC6g3AR8F/ihpOUkZxBnVys+MzPbX1U/RxcRi4HFRfM+k3ncBZxVzZjMzCyfv3FtZma5nCTMzCyXk4SZmeVykjAzs1xOEmZmlqtq35MYLpI2AJV/5ToxleT3oUYi163xjNR6getWjw6LiGkDFWr4JPF8SFpSzpdJGpHr1nhGar3AdWtkHm4yM7NcThJmZpZrtCeJRbUOYBi5bo1npNYLXLeGNaqvSZiZWf9G+5mEmZn1w0nCzMxyjdokIekUSY9KWi7polrHUwlJsyXdKukRSQ9L+nA6f4qkX0r6Y/p/cjpfkr6R1vVBSS+vbQ0GJqlZ0n2Sbk6nD5d0V1q3ayS1pvPb0unl6fK5tYx7IJImSbpe0h/S/nvVSOg3SX+X7osPSbpKUnuj9pmk70lan95OuTCv4j6SdG5a/o+Szq1FXYbCqEwSkpqBS4FTgfnAOZLm1zaqivQCH4uIFwGvBP42jf8i4FcRMQ/4VToNST3npX/nA9+sfsgV+zDwSGb6X4CvpXXbDJyXzj8P2BwRRwJfS8vVs38F/jsijgaOJaljQ/ebpEOBDwEdEfESkvvFnE3j9tkVwClF8yrqI0lTgM8CrwBOAD5bSCwNJyJG3R/wKuCWzPSngE/VOq7nUZ+fAq8HHgVmpvNmAo+mj78NnJMp31euHv9Ibm37K+C1wM2ASL7R2lLcfyQ3sXpV+rglLada1yGnXhOAFcXxNXq/AYcCK4EpaR/cDLyxkfsMmAs8NNg+As4Bvp2Zv0+5RvoblWcSPLdTF6xK5zWc9FT9ZcBdwPSIWAOQ/j84LdZo9f068Algbzp9ELAlInrT6Wz8fXVLl29Ny9ejI4ANwOXpUNp3JB1Ig/dbRKwGvgI8Dawh6YN7GBl9VlBpHzVE35VjtCYJlZjXcJ8FljQOuAH4SERs669oiXl1WV9JbwLWR8Q92dklikYZy+pNC/By4JsR8TJgB88NW5TSEHVLh1FOBw4HDgEOJBmGKdaIfTaQvLqMmDqO1iSxCpidmZ4FPFOjWAZF0hiSBPGjiPjPdPY6STPT5TOB9en8RqrvnwKnSXoSuJpkyOnrwCRJhdvtZuPvq1u6fCLJ/dHr0SpgVUTclU5fT5I0Gr3fTgZWRMSGiNgN/CfwJ4yMPiuotI8ape8GNFqTxN3AvPTTF60kF9luqnFMZZMk4LvAIxHx/zKLbgIKn6I4l+RaRWH+u9NPYrwS2Fo4da43EfGpiJgVEXNJ+uXXEfFO4FbgzLRYcd0KdT4zLV+XR2wRsRZYKemF6azXActo/H57GnilpAPSfbNQr4bvs4xK++gW4A2SJqdnWm9I5zWeWl8UqdUfsBB4DHgc+HSt46kw9j8jOXV9ELg//VtIMq77K+CP6f8paXmRfJrrcWApyadQal6PMup5EnBz+vgI4PfAcuA6oC2d355OL0+XH1HruAeo00uBJWnf3QhMHgn9BnwO+APwEPBDoK1R+wy4iuTaym6SM4LzBtNHwHvTOi4H/qrW9Rrsn3+Ww8zMco3W4SYzMyuDk4SZmeVykjAzs1xOEmZmlstJwszMcjlJmJlZLicJMzPL9f8Be/PwcSgH3e8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Where to hold the ham and spam posteriors\n",
    "posteriors = np.zeros((len(test_lines),2))\n",
    "\n",
    "# Loop over all the messages in the test set\n",
    "for i,m in enumerate(test_messages):\n",
    "    posterior_ham = 1.0 * ham_prior\n",
    "    posterior_spam = 1.0 *(1-ham_prior)\n",
    "    #! Don't forget to include the prior!\n",
    "    # Loop over all the words in each message\n",
    "    for w in m:\n",
    "        # #! What is the purpose of this try/except handler?\n",
    "        try:\n",
    "            posterior_ham *= ham_likelihood[w]\n",
    "            posterior_spam *= 1-ham_likelihood[w]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    # Notice the normalization factor (denominator) \n",
    "    # to turn these into proper probabilities!\n",
    "    posteriors[i,0] = posterior_spam/(posterior_spam + posterior_ham)\n",
    "    posteriors[i,1] = posterior_ham/(posterior_spam + posterior_ham)\n",
    "    \n",
    "print (posteriors[:5])\n",
    "print (np.percentile(posteriors[:,0],88))\n",
    "\n",
    "plt.scatter(range(len(posteriors[:,0])),posteriors[:,0],s=.7)\n",
    "\n",
    "plt.title(\"Probability of messages being spam\")\n",
    "plt.ylabel(\"$P(Spam)$\")\n",
    "\n",
    "#fig = figure()\n",
    "#ax = ax.subplot(1,1,1)\n",
    "#ax.scatter(range(len(posteriors[:,1])),posteriors[:,1], s=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make a ham/spam prediction based on your posterior probabilities.  Compare these to the labels contained in test_labels.  Report the accuracy of your classifier as percentage correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best results with Decision boundary at ~90% likely ham (could optimize!)\n",
    "# Although I should probably be more conservative to make sure \n",
    "# I dont exclude ham, its ok if I include spam once in awhile...\n",
    "# P(h)>=.1 is probably better for actual use\n",
    "# We should weight the minimizing # of hams misidentified as spams heavily\n",
    "# and weight the minimizing # of spams misidentified as hams relatively lightly...\n",
    "\n",
    "ham_predict = np.array([])\n",
    "decision_boundary = .1\n",
    "\n",
    "for i in posteriors[:,1]:\n",
    "    if i>=decision_boundary:\n",
    "        ham_predict = np.append(ham_predict, 1)\n",
    "    else:\n",
    "        ham_predict = np.append(ham_predict, 0)\n",
    "        \n",
    "number_correct=0\n",
    "\n",
    "for i in np.arange(len(ham_predict)):\n",
    "    if ham_predict[i] == test_labels[i]:\n",
    "        number_correct += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93627\n",
      "Percent correct:  93.6\n"
     ]
    }
   ],
   "source": [
    "print (str(np.round(number_correct/len(ham_predict),decimals=5)))\n",
    "print (\"Percent correct:  \" + str(np.round(100.*number_correct/len(ham_predict),decimals=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
